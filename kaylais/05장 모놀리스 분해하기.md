## 5. 모놀리스 분해하기  

> 모놀리스는 시간이 흐르면서 자라나고,  
> 빠른 속도로 새로운 기능과 코드 라인을 요구하며,  
> 머지않아 조직 내 사람들이 건드리거나 바꾸기를 두려워하는 거대하고 무서운 존재가 된다.  

### 좋은 접합부란?  
경계가 있는 콘텍스트(bounded context)  
조직 내의 응집력 있고, 느슨히 결합된 경계를 잘 표현  

### 리팩토링  
현대적 IDE에서 코드 이동은 리팩토링 기능을 통해 다른 작업 중에 자동적이고 점진적으로 이뤄질 수 있음  
하지만 코드 이동에 따른 오류를 잡아내기 위해 여전히 테스트가 필요  
시간이 지나면서 우리는 잘 어울려 남아 있는 코드와 그렇지 못한 코드를 알아가기 시작  
대게 끝까지 생존한 코드가 우리가 간과했을지 모를 경계가 있는 콘텍스트로 인식될 수 있음  
- 서비스를 분리하기 전에 모든 코드를 도메인에 따라 나눠진 패키지들에 따라 정렬할 필요는 없다  
- 한번에 모든 것을 바꾸려는 빅뱅(Big-bang) 접근법을 취할 필요는 없고, 이 과정을 천천히 조금씩 진행되는 것으로 인식  
- 뒤엉킨 모든 의존성의 출처가 대게 데이터베이스라는 것  

### 외부 키 관계 깨뜨리기  
특정 콘텍스트의 코드 내에 데이터베이스 맵핑 코드를 함께 배치하면 어떤 코드가 데이터베이스의 어느 부분을 사용하는지 이해할 수 있음  
예를 들어 경계가 잇는 콘텍스트 단위의 맵핑 파일과 같은 것을 사용한다면 하이버네이트에서는 매우 명확  
* 스키마스파이(SchemaSpy) : 테이블 관계를 그래픽으로 표현하는 도구  
이 모든 것은 궁극적으로 서비스 경계로 확장될 수 있는 테이블 간의 결합을 이해하도록 해줌  
- 보고서를 생성하기 위해 서로 다른 두 개의 데이터베이스에 호출해야 하는 것은 분명하며 옳은 것  

### 공유 데이터 분리  
- 각 패키지에 복제, 장기적으로 보면 그 테이블은 각 서비스 내부에서도 복제 될 수 있음  
- 공유 정적 데이터를 코드로 다루는 것  
  - 서비스의 부분으로 배포되는 속성 파일에 저장되거나,  
  - 열거형 개체(enumeration)가 될 수 있음  
  - 동작 중인 데이터베이스 테이블을 변경하는 것보다 설정 파일을 변경하는 것이 용이하나 데이터 일관성에 대한 문제는 여전히 존재  


### 트랜잭션의 경계  
애플리케이션 코드를 완전히 불리하여 각각의 마이크로서비스로 만들기 전에, 서비스는 이전과 같이 하나로 유지한 채 우선 스키마 분리를 추천  
서비스를 단계적으로 분리  
연산의 일부를 큐나 로그 파일에 큐잉하여 나중에 재시도 할 수 있음  

**보상 트랜잭션(compensating transaction)**  
직전의 트랜잭션을 되돌릴 새로운 트랜잭션을 발생시키는 것  

**분산 트랜잭션(distributed transaction)**  
보상 트랜잭션을 수동으로 통제하는 방식의 대안  
2단계 커밋(two-phase commit)  

### 데이터베이스 리팩토링  
모든 코드를 병합하기 전에는 관심사들이 실제로 통합되었는지 명확하지 않음  
다르게 저장될 수 있는 분리된 두 가지 개념이 있음  

### 리포팅 데이터베이스  
일반적인 모놀리식 서비스 아키텍처에서 모든 데이터는 거대한 단일 데이터베이스에 저장됨  
모든 데이터가 한 곳에 모여 있어서 모든 정보의 경계를 넘어서 리포팅하는 것이 실제로 매우 쉽다  
SQL 질의와 그와 유사한 것들을 통해 데이터를 쉽게 조인할 수 있기 때문  
리포팅 질의가 메인 시스템의 성능에 영향을 주는 것을 우려하여  
리포트를 메인 데이터베이스에서 실행하지 않을 것  
이에 리포팅 시스템은 대게 읽기용 복제 데이터베이스(read replica)에 연결됨  

#### 서비스 호출을 통한 데이터 추출  
- 데이터베이스 스키마는 실행 중인 모놀리식 서비스와 리포팅 시스템 사이에서 사실상 공유 API임  
	- 스키마의 변경은 조심스럽게 관리되어야 하며, 실제로 이것은 스키마를 변경하고 조율할 기회를 줄이는 방해물  
- 실제 시스템 또는 리포팅 시스템을 지원하는 사용 사례를 위해 데이터베이스를 최적하는 방법은 제한적  
	- 데이터 구조 변경이 실행 중인 시스템에 악영향을 주더라도 리포팅을 빠르게 하기 위해 데이터를 다르게 구성할 수 없음  
	- 스키마가 한 사용 사례에는 훌륭하게 들어맞지만 다른 사례에는 그렇지 못하거나 두 사례의 목적과 부합하지 않아 최소한의 공통분모만 가지게 되는 것  
- 일반적인 관계형 데이터베이스가 많은 리포팅 도구와 호환되는 SQL 질의 인터페이스를 제공하더라도 동작 중인 서비스에 데이터를 저장하기 위한 최선의 방법은 아님  

#### 데이터 덤프  
리포팅 시스템이 데이터를 끌어오는 방식 대신 리포팅 시스템에 데이터를 밀어 넣는 방식을 시도할 수 있다.   
일반적인 HTTP 호출로 데이터를 추출하는 데 있어 단점 중 하나는 다수의 호출을 할 때 발생하는 HTTP의 부하고  
리포팅 목적으로만 사용될지도 모르는 API를 만들어야 하는 부담이다.
-> 같은 데이터의 소스인 서비스의 데이터베이스에 직접 접근하여 리포팅 데이터베이스로 밀어 넣는 독립 프로그램을 가지는 것

**데이터마트**  
AWS S3를 실제로 거대한 데이터 마트로 위장하며, JSON 파일을 S3에 저장하기 위해 데이터 펌프를 사용함  
-> 솔루션이 확장이 필요할 때까지 아주 효과가 있었고, 엑셀과 태블로 같은 표준 리포팅 도구와 통합할 수 있는 큐브를 채우도록 이 펌프들을 변경하는 것을 검토  

#### 이벤트 데이터 펌프   
고객 서비스가 상태가 바뀌면 상태 변이 이벤트가 발행되고 고객 리포팅 맵퍼를 통해 중앙의 리포팅 데이터베이스로 펌프 됨  

#### 백업 데이터 펌프  
**넷플릭스**  
카산드라 데이터를 백업하기 위해 데이터 파일을 복사해서 안전한 곳에 저장  
SStable로 알려져있는 이런 파일들을 S3 객체 저장소에 저장  
이 백업된 데이터를 원본으로 사용하는 하둡을 통해 방대한 양의 데이터를 처리할 수 있는 파이프라인을 구현, 아이기스토스 프로젝트로 오픈소스화 됨  
하지만 데이터 펌프처럼 이 백업 데이터 펌프 패턴 역시 리포팅 스키마와 결합  

### 변경 비용  
데이터베이스를 분리하는 것은 더 많은 작업이 필요  
데이버베이스 변경을 되돌리는 것은 복잡한 일  
서비스들이 지나치게 결합된 통합을 분리하는 것 또는 다수의 소비자가 사용하는 API를 완전히 재작성하는 것은 상당히 큰 작업  
높은 비용이 드는 변경은 이들 작업이 점점 더 위험해진다는 것  

**화이트 보드**를 활용하여 디자인을 스케치, 서비스 경계를 넘어 실행할 때 어떤 일이 발생하는지 확인  
- 어떤 출이 발생하는가?  
- 이상한 순환 참조를 볼 수 있는가?  
- 지나치게 호출이 많은 두 서비스를 발견했는가?  

### CRC(class-responsibility-collaboration) Card  
CRC 카드로 색인 카드에 클래스의 이름, 그것의 책임, 누구와 협업하는지 기입  
제안된 디자인을 통해 작업할 때 각각의 서비스에 대해 그것이 제공하는 기능 측면에서의 책임과 다이어그램에 지정된 협업자를 나열  
더 많은 사용 사례를 통해 작업할 때 이 모든 것이 적절히 들어맞는지 감을 잡을 수 있을 것    

---

**접합부**  
seam  

**structure101**  
애자일 아키텍처 개발 환경으로, 코드베이스의 구조화를 돕기 위해 다양한 IDE를 위한 플러그인을 제공  

**SKU(Stock Keeping Unit)**  
개별 상별 상품에 대해 재고 관리 목적으로 추적이 쉽도록 하기 위해 사용하는 식별 관리 코드  

**Cassandra**  
컬럼 지향 데이터베이스(column-oriented database)로 대용량 확장이 매우 용이한 리포팅 시스템에 적합  
컬럼 지향 데이터베이스는 데이터를 열 단위로 저장  
