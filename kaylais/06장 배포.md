## 6. 배포  

지속적 통합과 지속적 배포를 살펴보자  

### 지속적 통합(CI/Continuous Integration)  
- CI를 통한 핵심 목표는 모든 사람이 서로 동기를 맞추는 것  
- 새롭게 체크인된 코드가 기존 코드와 적절히 통합됨을 보장함으로 달성할 수 있음  
- CI 서버는 아래에 대한 검증을 함  
  - 코드의 커밋을 감지  
  - 체크아웃  
  - 코드의 컴파일과 테스트 통과를 확인  

### CI 장점  
- 코드 품질에 대해 어느 정도 바른 피드백을 얻을 수 있음  
- 바이너리 산출물을 자동으로 생성  
  - 산출물의 빌드를 위한 모든 코드는 버전 관리 되므로 필요할 때 언제든지 다시 만들 수 있음  
  - 배포된 산출물의 코드를 찾을 수 있는 정도로 추적할 수 있음  
  - CI 도구 자체의 기능에 따라 코드와 산출물에 대해 어떤 테스트가 수행되었는지 확인 가능  

### 제즈 험블의 3가지 질문  
CI는 빠르고 신속한 변경을 위한 핵심적인 실천 사항  
CI 없이는 마이크로서비스를 향한 여정이 고통스러울 것  
CI 도구의 사용과 CI의 실천을 혼동하지 말 것  
CI 도구는 단지 이러한 접근을 가능하게 할 뿐  

- Q.하루에 한번 메인 브랜치에 체크인하는가?  
  - 여러분은 자신의 코드를 통합하는지 확인할 필요가 있다. 여러분 코드는 물론 다른 사람들이 변경한 코드 또한 자주 확인하지 않는다면 향후의 통합이 더 어려워진다. 여러분이 변경을 위해 단기 브랜치를 사용하고 있더라도 가능한 한 자주 메인 브랜치에 통합하라.  
- Q.변경을 확인할 테스트 집합이 있는가?  
  - 테스트를 하지 않는다면 통합해서 작동하는지 구문상으로만 알 수 있으며, 시스템의 동작을 중단시키는 것까지는 알 수 없다. 코드가 기대한 대로 동작하는지 검증하지 않는 CI는 CI가 아니다.  
- Q.빌드가 깨졌을 때 팀이 그것을 최우선으로 해결하는가?  
  - 녹색 빌드는 변경한 것이 안전하게 통합되었고, 적색 빌드는 마지막 변경이 통합되지 않았음을 의미한다. 우리는 빌드 문제의 해결과 관련 없는 추가적인 체크인을 중단해야 한다. 변경이 많이 적체되면 그 빌드를 해결할 시간이 급격히 늘어난다. 필자는 수일 동안 필드가 깨어진 채로 방치한 티과 함께 작업했었는데, 결국 빌드를 통화하는 데 엄청난 노력이 들었다.  

### CI를 마이크로서비스와 매핑하기  
실환경에 배포하기 전에 신속히 변경하고 확인할 수 있도록 마이크로서비스당 하나의 CI 빌드를 두는 것    
각 마이크로서비스는 각자의 CI 빌드에 매핑된 각각의 소스 코드 저장소를 가진다.  
팀의 소유권도 훨씬 명확히 정리되나. 즉, 서비스의 소유는 저장소와 빌드도 책임지는 것을 의미   
특정 마이크로서비스에 대해 어떤 테스트가 수행되어야 하는지 언제든지 알 수 있도록 테스트는 마이크로서비스 소스 코드가 있는 소스 컨트롤 시스템에 있어야 함   


### 빌드 파이프라인  
각 단계를 완료하면서 소프트웨어 과정을 추적하는 방법을 제공, 소프트웨어 품질에 대한 통찰력을 가지도록 도움  
**CD** 는 모든 체크인의 실환경 준비에 대한 지속적인 피드백을 얻고, 나아가 모든 체크인을 빠짐없이 릴리스 후보로 여기는 접근 방법   
체크인에서 실환경까지 소프트웨어를 입수하는 데 연관된 모든 프로세스를 모델링해야 하고,  
어떤 버전의 소프트웨어가 릴리스에 적용되었는지 알아야 한다.  
CD에서는 소프트웨어가 진행하는 수동과 자동화의 모든 단계를 모델링하는 다단게 빌드 파이프라인의 개념을 확장하여 이것을 수행한다.  

팀이 새로운 프로젝트, 특히 빈 종이에서 작업하는 것과 같은 전혀 개발되지 않은 프로젝트를 막 시작할 때는 서비스 정계를 확정하는 동안 많은 혼돈을 겪기 쉽기 때문에 도메인에 대해 충분히 이해할 때까지 초창기 서비스를 큰 부분으로 유지하는 것이 좋다.  

### 커스텀 이미지  
서버를 프로비저닝하기 위해 AWS와 일반적인 우분투 이미지를 사용하고 있다고 하자.  
첫 번째로 할 일, 자바 애플리케이션을 실행하기 위해 오라클 JVM을 설치하는 것  
이 간단한 과정은 5분 정도 소요되는데, 머신이 프로비저닝되는데 2~3분 정도, JVM을 설치하는데 3분 정도 소요  
그리고 나서야 실제로 소프트웨어 설치를 시작할 수 있음  

**on-demand computing platform/주문형 컴퓨팅 플랫폼**   
만약 하루에도 여러 번 확인하려 한다면 빠른 피드백을 제공하는 측면에서는 실제로 문제가 됨   
소프트웨어를 설치하기 전에 모든 필수 구성 요소가 설치될 떄까지 기다려야 하기 때문   
시스템이 제로-다운타임을 허용하지 않는다면 실환경에 배포 시 다운타임이 늘어날 수 있음   
7장에서는 green/blue 배포와 같은 모델은 구버전의 서비스를 오프라인하지 않고도 신버전의 서비스를 배포할 수 있게 하면서 이러한 불편을 완화   
이 기동 시간(spin-up time)을 줄이기 위한 한가지 방법은 공통적으로 의존하는 것들을 주입한 가상 머신 이미지를 만드는 것  

![커스텀 VM 이미지 생성하기](./images/create_a_custom_image_of_VM.jpeg)  

실제로 빠른 가동 시간으로 인해 넷플릭스는 자신들의 서비스를 AWS AMI로 생성하는 모델을 채택  
우리가 배포하고자 하는 서비스는 모든 다양한 환경에서 동일해야 함  


### 서비스 환경 구성  
단일 산출물을 생성하여 환경 구성을 분리해서 관리하는 것  
각 환경에 존재하는 propertise file 또는 설치 프로세스에 전달될 다른 매개 변수 같은 것이 될 수 있음  
대규모 마이크로서비스를 다룰 때 이용되는 다른 인기 있는 방법은 환경 구성을 제공하는 전용 시스템을 사용하는 것  


### 서비스와 호스트 매핑  
직접 물리적인 머신에 배포하고 있다면 물리적인 서버는 하나의 호스트로 매핑  
만약 가상화를 사용하고 있다면 하나의 물리적인 머신은 독립적인 많은 호스트로 매핑되고 각각은 하나 또는 더 많은 서비스를 가질 수 있음  

**1개의 호스트에 다중 서비스**  
- 모니터링이 어려움 : CPU 상태를 추적할 때 서비스가 독립적으로 사용한 CPU 상태를 추적해야 할까?  
- 하나의 서비스가 상당한 부하를 받고 있는 경우 : 다른 부분에 가용한 리소스가 줄어듬  
- 장애 분석의 어려움  
- 확장하기 위한 복잡한 노력이 필요  
- 한 호스트가 모든 것을 가지게 되면 결국 서비스의 요구 사항이 다르더라도 모두 같은 식으로 처리해야 할 것  

**on-demand computing platform**  
- 컴퓨팅 자원의 비용을 대폭 낮춤  
- 가상화 기술의 향상은 조직 내 호스팅된 인프라스트럭처에 대해서도 더 많은 유연성 제공  

**호스트당 단일 서비스**  
호스트당 단일 서비스 모델을 통해 쉬운 모니터링과 복원 기능을 제공  
호스트당 다수 서비스 모델의 부작용을 회피하고 잠재적으로 단일 장애 지점을 줄임  
한 호스트의 고장은 오직 하나의 서비스에만 영향을 미침  
![Only one service per host](./images/only_one_service_per_host.jpeg)  


### PaaS/Platform as a Service  
서비스로서의 플랫폼, 대표적으로 Heroku  
Heroku는 서비스의 실행을 처리할 뿐만 아니라 아주 단순한 방식으로 데이터베이스와 같은 서비스도 지원  
애플리케이션의 용도를 기반으로 autoscale을 시도하려는 PasS를 많이 사용했었지만 그 결과는 좋지 않았음  

### LXC/Linux Container  
분리된 가상의 호스트를 구분하고 통제하기 위해 프로세스들을 위한 분리된 프로세스 공간을 생성  
리눅스 상에서 프로세스는 특정 사용자에 의해 실행되고 설정된 permission을 기반으로 특정 기능을 사용  
프로세스는 다른 프로세스를 생성 할 수 있음  
터미널에서 프로세스를 실행시키면 생성된 자식 프로세스는 일반적으로 터미널 프로세스의 자식으로 간주  
리눅스 커널의 역할은 이러한 프로세스 트리를 관리하는 것  

- 무거운 가상화 머신보다 프로비저닝이 훨씬 빠름  
- VM이 시작하는 데 수분이 걸린다는 것은 특이한 일이 아님, 하지만 LXC는 몇 초 만에 시작  
- 컨테이너는 또한 리소스 할당 면에서도 더 세세한 통제가 가능, 하부의 하드웨어를 최대한 활용하기 위한 손쉬운 미세 설정  
- 경량 컨테이너로 동일한 하드웨어서 VM보다 더 많은 컨테이너를 실행시킬 수 있음  
![Service in operation in a detached container](./images/service_in_operation_in_a_detached_container.jpeg)  

> AWS EC2 Instance를 프로비전하고 그 안에서 LXCs 실행  
> 매우 유연한 EC2의 형태로 대표되는 on-demand computing platform과   
> 그 위에서 빠르게 실행되는 컨테이너의 조합   

### Docker  
경량 컨테이너 상에 구축된 플랫폼  
도커는 애플리케이션(VM 세계에서의 이미지와 같은 의미)을 생성하고 배포할 수 있음  
컨테이너 프로비저닝을 관리  
네트워킹 문제를 처리  
도커 애플리케이션을 저장하고 버전을 관리할 수 있도록 자체 레지스트리 개념까지 제공  
서비스를 구현하는 데 사용된 하부의 기술을 은폐하므로 유용  
서비스를 위해 도커 애플리케이션을 생성하도록 빌드하고 도커 레지스트리에 저장하면 끝  
도커는 개발 및 테스트 목적으로 많은 서비스를 가까이에서 실행시킬 때의 일부 단점을 완화할 수 있음  

**도커를 단일 머신에서 작동하는 단순한 PasS라고 생각하라**  
컨테이너를 요청하고 실행할 수 있는 도커 컨테이너를 찾아내는 스케줄링 계층이 필수적 요구
구글이 최근 오픈 소스화한 쿠버네티스도 있다    

**Kubernetes**  
구글이 고안한 호스트 클러스트들의 경계를 넘어 애플리케이션 컨테이너의 자동 배포, 확장, 운영을 위한 오픈소스 플랫폼  


### 배포 인터페이스  
어떤 배포도 실행시킬 수 있는 가장 타당한 방법은? 매개 변수 전달이 가능한 한 줄의 명령행 호출임을 확신  
이것은 CI 도구에 의해 실행되는 스크립트로 또는 직접 입력함으로써 시작할 수 잇음  

세 개의 매개 변수를 입력받는 간단한 deploy 스크립트를 작성한다고 가정하자  

```shell  
# catalog service를 local 환경에서 배포  
$ deploy artifact=catalog environment=local version=local  
```  

```shell  
# 환경의 테스트가 시작되면 CI 스테이지 실행  
$ deploy artifact=catalog environment=ci version=b456  
```  

```shell  
# QA팀은 최신 버전의 제품 목록 서비스를 통합 테스트 환경에 끌어온다
$ deploy artifact=catalog environment=integrated_qa version=latest   
```   

가장 많이 사용한 도구는 패브릭  
SSH와 같이 원격 머신에 대한 작업을 쉽게 지원할 수 있도록 명령행 호출을 함수로 매핑하도록 설계된 파이썬 라이브러리  

**서비스가 하나 이상의 인스턴스를 가졌을 때**  
자동적으로 부하 분산기를 설정(AWS의 경우 ELB)  


---  
**downtime**  
시스템에 장애가 발생하여 시스템의 주요 기능을 제공하거나 수행이 불가한 기간  

**Digital Ocean**  
미국 뉴욕에 본사를 두고 글로벌 데이터 센터를 소유한 클라우드 인프라스트럭처 제공자  
개발자가 동시에 많은 가상 서버에서 배포하고 확장할 수 있는 클라우드 서비스를 제공  

**host**  
AWS의 경우 EC2 Instance  

**IPTable**  
리눅스 커널 방화벽이 제공하는 테이블과 그곳에 저장된 체인 및 규칙을 시스템 관리자가 설정할 수 있는 사용자 영역 애플리케이션 프로그램  
