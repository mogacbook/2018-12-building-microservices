대규모 마이크로서비스
=====

### 장애는 어디에서나 발생한다
>>어떤 장애든 결국 발생한다는 것을 가정하여 장애에 대한 계획을 세운다면 다양한 절충안을 준비할 수 있다.
***
<br/>

### 얼마나 많아야 너무 많은 건가?
부하와 장애를 더 잘 처리하기 위해 시스템 확장 방법을 고려한다면 다음 요구사항을 이해하는 것에서 출발하라
- 응답시간/지연시간
- 가용성
- 데이터의 내구성
***                          
<br/>

### 기능 분해
>>회복력 있는 시스템 구축에서 가장 중요한 중 하나는 안전하게 기능을 분해할 수 있는 능력(특히 동작 또는 다운 중일 수 있는 다양하고 수많은 마이크로서비스에 기능이 확산되어 있을 때)

교차기능 요구 사항의 관점에서 개별 기능의 심각도를 생각함으로써 우리가 무엇을 할 수 있는지 훨씬 더 잘 알게 될 것<br/>
장애가 발생할 때 우아하게 처리할 수 있도록 기술적인 관점에서 가능한 일들을 고려

***
<br/>

### 아키텍처 안전 조치
무언가 잘못될 때 벌어지는 심각한 파급 효과를 막기 위해 이용하는 몇 가지 패턴 통칭
>> 나쁜 시민 한 명이 시스템 세상 전체를 망가뜨리지 않도록 시스템에 표준화를 강력히 고려해야 한다.
***
<br/>

### 안티프래질 조직
실패와 무질서로부터 얻을 수 있는 혜택 - "나심 탈레브"의 저서 "안티프레질"
>> 넥플릭스는 장애에 강한 시스템을 보장하기 위해 실제로 장애를 자장하며 이를 극복했다. 넷플릭스는 자앵를 만들고 그 장애에 대응하도록 구축함으로써 확장이 잘되고 고객의 요구도 잘 지원하는 시스템을 보장했다.<br/>
>> 넷플릭스는 발생한 장애가 주는 교훈의 중요성과 실수를 해도 비난하지 않느 ㄴ문화를 수용하는 중요성을 잘 알았고 각 개발자는 실환경에서 자신의 서비스를 관리할 책임도 있으므로 배우고 진화하는 이 과정에 더욱 적극적으로 참여하게 되었다<br/>
>> 이런 종류의 정기적 연습을 통해 많은 조직이 혜택을 받을 것으로 확신한다.

#### 타임아웃
모든 프로세스 경계 외부의 호출에 타임아웃을 넣고 항상 기본 타임아웃 시간을 설정하라<br/>
타임아웃 발생 시간을 보장하고 어떤 일이 발생했늕 살펴보며 타임아웃을 적젏 변경하라
#### 회로 차단기
가정의 회로 차단기(전력이 급등하면 회로 차단기가 내려가서 가전 기기 보호, 직접 회로 차단기를 내릴 수도 있음)와 같이 소프트웨어를 위한 보호 메커니즘을 적용할 수 있다.<br/>
#### 격벽
"마이클 나이가드"는 저서 "릴리스 잇: 성공적인 출시를 위한 소프트웨어 설계와 배치"에서 장애를 격리하기 위한 방법으로 적벽의 개념 소개<br/>
적벽은 선박에서 배의 나머지 부분을 보호하기 위해 밀봉 역할을 하는 선체의 벽을 의미<br/>
>> 타임아웃과 회로차단기는 리소스가 제한될 때 그 것을 확보하는데 도움이 되지만 적벽은 처음부터 리소스가 제한되지 않게 할 수 있다.<br/>
>> 예 : 히스트릭스는 리소스가 더 소진되지 않도록 특정 조건에서 요청을 거부할 수 있는 적벽을 구현하게 해준다. 이 것은 부하 차단으로 알려진 것으로 가끔은 요청을 거부하는 것이 다수의 상향 서비스 때문에 중요한 시스템이 압도되거나 병목구간이 되는 것을 막는 최선의 방법이 된다.
#### 격리
서비스들이 서로 분리되면 서비스 소유자 간에 조율할 것도 줄여든다. 팀 간 조율이 적어질수록 더 자유롭게 서비스를 운영하고 발전시킬 수 있기 때문에 팀의 자율성은 높아진다.
***
<br/>

### 멱등성
연산이 연속적으로 여러 번 적용되더라도 첫 적용 후의 결과가 달라지지 않는 성질의 연산을 멱등연산이라고 한다<br/>
연산이 멱등적이라는 것은 역효과없이 호출을 반복할 수 있음을 의미, 이 것은 에러를 복구하는 일반적인 방법으로 처리가 확실하지 않은 메시지를 재생할 때 매우 유용<br/>
>> 이 매커니즘은 이벤트 기반의 공도 ㅇ작업과 궁함이 맞으며 이벤트를 구독하는 동일 유형의 서비스 인스턴스가 여러개 있는 경우 특히 유용, <br/>
>> 우리가 어떤 이벤트를 처리해야 저장하더라도 비동기 메시지 전달 형태에는 두 작업자 서비스가 동일한 메시지를 바라볼 수 있는 작은 창이 존재할 수 있다. 우리는 이벤트를 멱등 방식으로 처리함으로써 어떤 문제도 일어나지 않게 보장한다.
***
<br/>

### 확장
>> 일반적으로 둘 중 한가지 이유로 시스템을 확장한다.<br/>
>> 첫째 장애에 더 잘 대응하기 위해, 둘째 성능을 위해
#### 더 크게 만들기
보통 더 큰 머신에 더 빠른 CPU와 더 좋은 I/O를 탑재하면 더 짧은 시간에 더 많은 일을 처리하며 지연시간과 처리량을 향상시킬 수 있으나 수직확장으로 알려진 이 확장 형태는 고비용이다 <br/>
이 확장 형태의 또 다른 문제는 한 대의 서버만 있을 경우 서버의 탄력성이 크게 향상되지 않는다는 것<br/>
그럼에도 불구하고 수직 확장은 빠르고 좋은 해결 방안이며 머신 크기를 쉽게 변경할 수 있는 가상화제공자를 사용 중이라면 더욱 그렇다
#### 작업부하 나누기
마이크로서비스는 네트워크를 통해 통신하는 독립 프로세스이기 때문에 처리량과 확장성을 향상시키기 위해 서비스를 각가의 호스트로 옮기는 것이 쉽다. 그리고 이 상황에서 단일 호스트 장애는 호스트 안의 줄어든 마이크로서비스에 영향을 줄 수 있기 때문에 시스템의 탄력성 역시 높일 수 있다.<br/>
물론 부하를 더 효과적으로 처리하도록 기존의 마이크로서비스를 더 작은 부분으로 쪼개기 위해 확장할 필요가 있다.
#### 위험 분산
회복성을 위해 확장하는 한 가지 방법은 계란은 한 바구니에 담지 않는 것이다<br/>
장애를 줄이기 위해 분리의 일반적 형태는 모든 서비스를 데이터 센터의 단일 랙엥서 실행하지 않거나 서비스를 여러 데이터 센터로 분사하는 것, 그리고 하부 서비스 제공자를 이용한다면 서비스 수준 계약(SLA)이 적절히 제공되고 계획될 수 있는지 여부가 중요하다<br/>
공급자의 장애로 인한 영향도를 잘 이해하고 여러분 자체의 플랜 B나 C를 마련해야한다<br/>
예) 어떤 기업은 한 공급자의 실수에 취약하지 않도록 서로 다른 공급자에 의해 제공된 재해 복구 호스팅 플랫폼을 보유
#### 부하 분산
부하 분산기는 고용량 고비용의 하드웨어 장비에서 모드 프록시와 같은 소프트웨어 기반의 것까지 그 형태와 크기가 다양<br/>
모든 부하 분산기는 몇 가지 핵심 기능을 제공하는데 유입된 호출을 주어진 알고리즘에 따라 하나 이상의 인스턴스에 분해, 인스턴스가 정상 동작 하지 않거나 복구되었을 때 제거하거나 추가한다.<br/>
일부 부하 분산기는 유용한 기능을 제공하는데 대표적인 것이 SSL 종단 기능 <br/>
SSL 종단 기능을 사용하면 우리 자신을 잠재적으로 노출하는 것인데 완화 방안은 VLAN안에 모든 마이크로서비스 인스턴스를 두는 것<br/>
VLAN - 가상의 지역네트워크, 외부와 격리되어 있어 외부의 요청은 라우터를 통해서만 유입<br/>
AWS - HTTP 종단기능이 있는 부하 분산기를 ELB 형태로 제공, VLAN을 구현하기 위해 AWS 보안 그룹이나 가상 사설 클라우드를 사용<br/>
부하 분산기는 서비스 소비자가 인식 못하느 ㄴ방식으로 더 많은 마이크로서비스 인스턴스를 추가할 수 있게 해주며 이 것은 부하를 처리하는 향상된 능력과 한 호스트의 장애에 대한 영향도를 낮추는 향상된 능력도 제공
#### 작업자 기반 시스템
부하 분산이 서비스의 다수 인스턴스가 부하를 공유하고 취약함을 줄이기 위한 유일한 방법은 아님<br/>
운영 특성에 따라 작업자 기반 시스템이 부하 분산 못지않게 효과적일 수 있음<br/>
작업자 기반 시스템에서는 작업자 자체가 신뢰성이 높을 필요는 없더라도 그 작업을 완료해야 하는 시스템은 신뢰성이 있어야 함<br/>
예 - 영속 메시지 브로커 또는 주키퍼와 같은 시스템을 이용, 이를 구현할 수 있어야 함
#### 다시 시작하기
>> 10배 성장까지 고려해서 설계하고 100배 성장 전까지 재작성을 계획해야 한다고 강조!<br/>
>> 제프 딘의 '대규모 정보 시스템 구축에 대한 도전' 중 - WSDM 2009 컨퍼런스

처음부터 대규모 확장을 대비해 구축해야 한다는 이유로 특정 확장 임계점에 도달할 때 구조적 재설계가 필요하다고 느끼는 것은 위험<br/>
확장하기 위해 시스템을 변경하 ㄹ필요가 있다면 이 것은 실패가 아닌 성공의 징조!
***
<br/>

### 데이터베이스 확장
>> 데이터베이스 종류가 다르면 다른 확장 방식이 필요하고 실제 사용 사례에 최적화된 바ㅓㅇ식을 이해하면 처음부터 올바른 데이터베이스 기술을 선택할 수 있다.
#### 서비스의 가용성과 데이터의 내구성
서비스의 가용성과 데이터의 내구성 개념을 분리하는 것은 중요 - 이 두 개념은 서로 다르고 따라서 다른 해결책이 있음에 대한 이해 필요<br/>
데이터베이스에 저장된 모든 데이터가 대기 복제 데이터베이스에 복사, 주 데이터베이스가 다운될 경우 데이터는 안전하지만 주 데이터베이스를 백업으로 바꾸거나 복제 데이터베이스를 주 데이터베이스를 승격시키는 매커니즘 없이는 데이터베이스의 가용성을 얻을 수 없음
#### 읽기용 확장
관계형 데이터베이스 관리 시스템에서는 데이터는 주 노드에서 하나 이상 복제복으로 복사된다. 이 것은 대개 데이터의 복제본이 안전하게 보관되는 것을 보장하지만 읽기를 분산하는 용도로 사용될 수 있다.
#### 쓰기용 확장
쓰기용 확장의 한가지 방안은 샤딩을 사용하는 것으로 많은 데이터베이스 노드를 가질 수 있음<br/>
쓰기용 샤딩의 복잡성은 질의를 처리할 때 발생, 여러샤드에 대한 잦은 질의는 캐시 결과를 사용해서 비동기적 매커니즘으로 처리<br/>
샤딩된 시스템에 대한 질문 중 하나는 데이터베이스 노드를 추가하는 방법에 관한 것으로 과거에는 데이터베이스 전체르 ㄹ다운, 데이터를 재조정해야할 필요가 있어 다운타임이 필요했으나 최근에는 많은 시스템이 백그라운드에서 데이터의 재조정을 수행하면서 라이브 시스템에도 샤드 추가를 지원(예 - 카산드라는 이 기능을 매우 잘 처리)<br/>
>> 쓰기용 데이터베이스 확장은 까다로우며 데이터베이스 기능이 실제로 차별화 되는 곳<br/>
>> 쓰기 볼륨을 쉽게 확장할 수 없는 한계에 부딪혓을 때 ...<br/>
>> 큰 박스(하드웨어)를 구매하는 것이 가장 빠른 방법이나 카산드라, 몽고디비 또는 리악과 같은 대체 시스템의 확장 모델이 장기적으로 더 나은 솔루션을 제공할 수 있는지 확인하기 위해 이들 시스템을 내부적으로 검토하고 싶을 것...?
#### 공유 데이터베이스 인프라스트럭처
전통적인 RDBMS와 같은 일부 데이터베이스는 데이터베이스 자체와 스키마의 개념을 분리함, 이는 동작 중인 데이터베이스가 독립적인 다수의 스키마를 호스팅할 수 있다는 것을 의미 -> 그러나 명백한 단일 장애 지점이 될 수 있음<br/>
데이터베이스 인프라스트럭처가 다운된다면 한번에 다수의 마이크로 서비스에 영향을 주고 잠재적 대/재/앙<br/>
이런 설정 유형으로 운영하고 있다면 위험을 확실히 고려하고 데이터베이스 자체가 최대한 회복력이 있는지 반드시 확인
#### CQRS (명령과 질의에 대한 책임 분리)
CQRS는 정보를 저장하고 질의하기 위한 대안 모델로 언급<br/>
CQRS를 사용하면 시스템의 일부가 명령을 처리, 상태를 변경하는 요청을 캡처하며 시스템의 다른 부분이 질의를 처리<br/>
주요 시사점 - 명령과 질의를 처리하는 데 사용된 내부 모델들은 그 자체로 완전한 분리된다는 것<br/>
이런 형태의 분리는 다양한 종류의 확장을 가능하게 하며 다양한 질의 구현을 통해 다양한 종류의 읽기 포맷을 지원할 수 있음<br/>
***
<br/>

### 캐싱
#### 클라이언트 측, 프록시, 그리고 서버 측 캐싱
#### HTTP 캐싱
#### 쓰기용 캐싱
#### 회복성을 위한 캐싱
#### 원본 감추기
#### 단순화하라
#### 캐시 중독: 경계할 일화
***
<br/>

### 자동 확장
***
<br/>

### CAP 정리
#### 일관성 희생하기
#### 가용성 희생하기
#### 분할용인 희생하기?
#### AP 또는 CP?
#### 양자택일이 아니다
#### 그리고 현실세계
***
<br/>

### 서비스 발견
#### DNS
***
<br/>

### 동적 서비스 레지스트리
#### 주키퍼
#### 칸슬
#### 유레카
#### 직접 만들기
#### 사람을 잊지 마라!
***
<br/>

### 문서화 서비스
#### 스웨거
#### HAL과 HAL 브라우저
***
<br/>

### 자기 기술 시스템
***
<br/>

### 마치며
***
<br/>
