대규모 마이크로서비스
=====

### 장애는 어디에서나 발생한다
>>어떤 장애든 결국 발생한다는 것을 가정하여 장애에 대한 계획을 세운다면 다양한 절충안을 준비할 수 있다.
***
<br/>

### 얼마나 많아야 너무 많은 건가?
부하와 장애를 더 잘 처리하기 위해 시스템 확장 방법을 고려한다면 다음 요구사항을 이해하는 것에서 출발하라
- 응답시간/지연시간
- 가용성
- 데이터의 내구성
***                          
<br/>

### 기능 분해
>>회복력 있는 시스템 구축에서 가장 중요한 중 하나는 안전하게 기능을 분해할 수 있는 능력(특히 동작 또는 다운 중일 수 있는 다양하고 수많은 마이크로서비스에 기능이 확산되어 있을 때)

교차기능 요구 사항의 관점에서 개별 기능의 심각도를 생각함으로써 우리가 무엇을 할 수 있는지 훨씬 더 잘 알게 될 것<br/>
장애가 발생할 때 우아하게 처리할 수 있도록 기술적인 관점에서 가능한 일들을 고려

***
<br/>

### 아키텍처 안전 조치
무언가 잘못될 때 벌어지는 심각한 파급 효과를 막기 위해 이용하는 몇 가지 패턴 통칭
>> 나쁜 시민 한 명이 시스템 세상 전체를 망가뜨리지 않도록 시스템에 표준화를 강력히 고려해야 한다.
***
<br/>

### 안티프래질 조직
실패와 무질서로부터 얻을 수 있는 혜택 - "나심 탈레브"의 저서 "안티프레질"
>> 넥플릭스는 장애에 강한 시스템을 보장하기 위해 실제로 장애를 자장하며 이를 극복했다. 넷플릭스는 자앵를 만들고 그 장애에 대응하도록 구축함으로써 확장이 잘되고 고객의 요구도 잘 지원하는 시스템을 보장했다.<br/>
>> 넷플릭스는 발생한 장애가 주는 교훈의 중요성과 실수를 해도 비난하지 않느 ㄴ문화를 수용하는 중요성을 잘 알았고 각 개발자는 실환경에서 자신의 서비스를 관리할 책임도 있으므로 배우고 진화하는 이 과정에 더욱 적극적으로 참여하게 되었다<br/>
>> 이런 종류의 정기적 연습을 통해 많은 조직이 혜택을 받을 것으로 확신한다.

#### 타임아웃
모든 프로세스 경계 외부의 호출에 타임아웃을 넣고 항상 기본 타임아웃 시간을 설정하라<br/>
타임아웃 발생 시간을 보장하고 어떤 일이 발생했늕 살펴보며 타임아웃을 적젏 변경하라
#### 회로 차단기
가정의 회로 차단기(전력이 급등하면 회로 차단기가 내려가서 가전 기기 보호, 직접 회로 차단기를 내릴 수도 있음)와 같이 소프트웨어를 위한 보호 메커니즘을 적용할 수 있다.<br/>
#### 격벽
"마이클 나이가드"는 저서 "릴리스 잇: 성공적인 출시를 위한 소프트웨어 설계와 배치"에서 장애를 격리하기 위한 방법으로 적벽의 개념 소개<br/>
적벽은 선박에서 배의 나머지 부분을 보호하기 위해 밀봉 역할을 하는 선체의 벽을 의미<br/>
>> 타임아웃과 회로차단기는 리소스가 제한될 때 그 것을 확보하는데 도움이 되지만 적벽은 처음부터 리소스가 제한되지 않게 할 수 있다.<br/>
>> 예 : 히스트릭스는 리소스가 더 소진되지 않도록 특정 조건에서 요청을 거부할 수 있는 적벽을 구현하게 해준다. 이 것은 부하 차단으로 알려진 것으로 가끔은 요청을 거부하는 것이 다수의 상향 서비스 때문에 중요한 시스템이 압도되거나 병목구간이 되는 것을 막는 최선의 방법이 된다.
#### 격리
서비스들이 서로 분리되면 서비스 소유자 간에 조율할 것도 줄여든다. 팀 간 조율이 적어질수록 더 자유롭게 서비스를 운영하고 발전시킬 수 있기 때문에 팀의 자율성은 높아진다.
***
<br/>

### 멱등성
연산이 연속적으로 여러 번 적용되더라도 첫 적용 후의 결과가 달라지지 않는 성질의 연산을 멱등연산이라고 한다<br/>
연산이 멱등적이라는 것은 역효과없이 호출을 반복할 수 있음을 의미, 이 것은 에러를 복구하는 일반적인 방법으로 처리가 확실하지 않은 메시지를 재생할 때 매우 유용<br/>
>> 이 매커니즘은 이벤트 기반의 공도 ㅇ작업과 궁함이 맞으며 이벤트를 구독하는 동일 유형의 서비스 인스턴스가 여러개 있는 경우 특히 유용, <br/>
>> 우리가 어떤 이벤트를 처리해야 저장하더라도 비동기 메시지 전달 형태에는 두 작업자 서비스가 동일한 메시지를 바라볼 수 있는 작은 창이 존재할 수 있다. 우리는 이벤트를 멱등 방식으로 처리함으로써 어떤 문제도 일어나지 않게 보장한다.
***
<br/>

### 확장
>> 일반적으로 둘 중 한가지 이유로 시스템을 확장한다.<br/>
>> 첫째 장애에 더 잘 대응하기 위해, 둘째 성능을 위해
#### 더 크게 만들기
보통 더 큰 머신에 더 빠른 CPU와 더 좋은 I/O를 탑재하면 더 짧은 시간에 더 많은 일을 처리하며 지연시간과 처리량을 향상시킬 수 있으나 수직확장으로 알려진 이 확장 형태는 고비용이다 <br/>
이 확장 형태의 또 다른 문제는 한 대의 서버만 있을 경우 서버의 탄력성이 크게 향상되지 않는다는 것<br/>
그럼에도 불구하고 수직 확장은 빠르고 좋은 해결 방안이며 머신 크기를 쉽게 변경할 수 있는 가상화제공자를 사용 중이라면 더욱 그렇다
#### 작업부하 나누기
마이크로서비스는 네트워크를 통해 통신하는 독립 프로세스이기 때문에 처리량과 확장성을 향상시키기 위해 서비스를 각가의 호스트로 옮기는 것이 쉽다. 그리고 이 상황에서 단일 호스트 장애는 호스트 안의 줄어든 마이크로서비스에 영향을 줄 수 있기 때문에 시스템의 탄력성 역시 높일 수 있다.<br/>
물론 부하를 더 효과적으로 처리하도록 기존의 마이크로서비스를 더 작은 부분으로 쪼개기 위해 확장할 필요가 있다.
#### 위험 분산
회복성을 위해 확장하는 한 가지 방법은 계란은 한 바구니에 담지 않는 것이다<br/>
장애를 줄이기 위해 분리의 일반적 형태는 모든 서비스를 데이터 센터의 단일 랙엥서 실행하지 않거나 서비스를 여러 데이터 센터로 분사하는 것, 그리고 하부 서비스 제공자를 이용한다면 서비스 수준 계약(SLA)이 적절히 제공되고 계획될 수 있는지 여부가 중요하다<br/>
공급자의 장애로 인한 영향도를 잘 이해하고 여러분 자체의 플랜 B나 C를 마련해야한다<br/>
예) 어떤 기업은 한 공급자의 실수에 취약하지 않도록 서로 다른 공급자에 의해 제공된 재해 복구 호스팅 플랫폼을 보유
#### 부하 분산
부하 분산기는 고용량 고비용의 하드웨어 장비에서 모드 프록시와 같은 소프트웨어 기반의 것까지 그 형태와 크기가 다양<br/>
모든 부하 분산기는 몇 가지 핵심 기능을 제공하는데 유입된 호출을 주어진 알고리즘에 따라 하나 이상의 인스턴스에 분해, 인스턴스가 정상 동작 하지 않거나 복구되었을 때 제거하거나 추가한다.<br/>
일부 부하 분산기는 유용한 기능을 제공하는데 대표적인 것이 SSL 종단 기능 <br/>
SSL 종단 기능을 사용하면 우리 자신을 잠재적으로 노출하는 것인데 완화 방안은 VLAN안에 모든 마이크로서비스 인스턴스를 두는 것<br/>
VLAN - 가상의 지역네트워크, 외부와 격리되어 있어 외부의 요청은 라우터를 통해서만 유입<br/>
AWS - HTTP 종단기능이 있는 부하 분산기를 ELB 형태로 제공, VLAN을 구현하기 위해 AWS 보안 그룹이나 가상 사설 클라우드를 사용<br/>
부하 분산기는 서비스 소비자가 인식 못하느 ㄴ방식으로 더 많은 마이크로서비스 인스턴스를 추가할 수 있게 해주며 이 것은 부하를 처리하는 향상된 능력과 한 호스트의 장애에 대한 영향도를 낮추는 향상된 능력도 제공
#### 작업자 기반 시스템
부하 분산이 서비스의 다수 인스턴스가 부하를 공유하고 취약함을 줄이기 위한 유일한 방법은 아님<br/>
운영 특성에 따라 작업자 기반 시스템이 부하 분산 못지않게 효과적일 수 있음<br/>
작업자 기반 시스템에서는 작업자 자체가 신뢰성이 높을 필요는 없더라도 그 작업을 완료해야 하는 시스템은 신뢰성이 있어야 함<br/>
예 - 영속 메시지 브로커 또는 주키퍼와 같은 시스템을 이용, 이를 구현할 수 있어야 함
#### 다시 시작하기
>> 10배 성장까지 고려해서 설계하고 100배 성장 전까지 재작성을 계획해야 한다고 강조!<br/>
>> 제프 딘의 '대규모 정보 시스템 구축에 대한 도전' 중 - WSDM 2009 컨퍼런스

처음부터 대규모 확장을 대비해 구축해야 한다는 이유로 특정 확장 임계점에 도달할 때 구조적 재설계가 필요하다고 느끼는 것은 위험<br/>
확장하기 위해 시스템을 변경하 ㄹ필요가 있다면 이 것은 실패가 아닌 성공의 징조!
***
<br/>

### 데이터베이스 확장
>> 데이터베이스 종류가 다르면 다른 확장 방식이 필요하고 실제 사용 사례에 최적화된 바ㅓㅇ식을 이해하면 처음부터 올바른 데이터베이스 기술을 선택할 수 있다.
#### 서비스의 가용성과 데이터의 내구성
서비스의 가용성과 데이터의 내구성 개념을 분리하는 것은 중요 - 이 두 개념은 서로 다르고 따라서 다른 해결책이 있음에 대한 이해 필요<br/>
데이터베이스에 저장된 모든 데이터가 대기 복제 데이터베이스에 복사, 주 데이터베이스가 다운될 경우 데이터는 안전하지만 주 데이터베이스를 백업으로 바꾸거나 복제 데이터베이스를 주 데이터베이스를 승격시키는 매커니즘 없이는 데이터베이스의 가용성을 얻을 수 없음
#### 읽기용 확장
관계형 데이터베이스 관리 시스템에서는 데이터는 주 노드에서 하나 이상 복제복으로 복사된다. 이 것은 대개 데이터의 복제본이 안전하게 보관되는 것을 보장하지만 읽기를 분산하는 용도로 사용될 수 있다.
#### 쓰기용 확장
쓰기용 확장의 한가지 방안은 샤딩을 사용하는 것으로 많은 데이터베이스 노드를 가질 수 있음<br/>
쓰기용 샤딩의 복잡성은 질의를 처리할 때 발생, 여러샤드에 대한 잦은 질의는 캐시 결과를 사용해서 비동기적 매커니즘으로 처리<br/>
샤딩된 시스템에 대한 질문 중 하나는 데이터베이스 노드를 추가하는 방법에 관한 것으로 과거에는 데이터베이스 전체르 ㄹ다운, 데이터를 재조정해야할 필요가 있어 다운타임이 필요했으나 최근에는 많은 시스템이 백그라운드에서 데이터의 재조정을 수행하면서 라이브 시스템에도 샤드 추가를 지원(예 - 카산드라는 이 기능을 매우 잘 처리)<br/>
>> 쓰기용 데이터베이스 확장은 까다로우며 데이터베이스 기능이 실제로 차별화 되는 곳<br/>
>> 쓰기 볼륨을 쉽게 확장할 수 없는 한계에 부딪혓을 때 ...<br/>
>> 큰 박스(하드웨어)를 구매하는 것이 가장 빠른 방법이나 카산드라, 몽고디비 또는 리악과 같은 대체 시스템의 확장 모델이 장기적으로 더 나은 솔루션을 제공할 수 있는지 확인하기 위해 이들 시스템을 내부적으로 검토하고 싶을 것...?
#### 공유 데이터베이스 인프라스트럭처
전통적인 RDBMS와 같은 일부 데이터베이스는 데이터베이스 자체와 스키마의 개념을 분리함, 이는 동작 중인 데이터베이스가 독립적인 다수의 스키마를 호스팅할 수 있다는 것을 의미 -> 그러나 명백한 단일 장애 지점이 될 수 있음<br/>
데이터베이스 인프라스트럭처가 다운된다면 한번에 다수의 마이크로 서비스에 영향을 주고 잠재적 대/재/앙<br/>
이런 설정 유형으로 운영하고 있다면 위험을 확실히 고려하고 데이터베이스 자체가 최대한 회복력이 있는지 반드시 확인
#### CQRS (명령과 질의에 대한 책임 분리)
CQRS는 정보를 저장하고 질의하기 위한 대안 모델로 언급<br/>
CQRS를 사용하면 시스템의 일부가 명령을 처리, 상태를 변경하는 요청을 캡처하며 시스템의 다른 부분이 질의를 처리<br/>
주요 시사점 - 명령과 질의를 처리하는 데 사용된 내부 모델들은 그 자체로 완전한 분리된다는 것<br/>
이런 형태의 분리는 다양한 종류의 확장을 가능하게 하며 다양한 질의 구현을 통해 다양한 종류의 읽기 포맷을 지원할 수 있음<br/>
***
<br/>

### 캐싱
>> 캐싱은 일반적으로 사용되는 성능 최적화 방법<br/>
>> 연산의 이전 결과를 저장, 연속된 요청은 재연산을 위한 시간과 자원의 소비 없이 저장되어 있는 값을 사용할 수 있다<br/>
>> 대개 캐싱은 결과를 더 빠르게 제공하기 위해 데이터베이스나 다른 서비스까지의 불필요한 왕복을 제거, 잘 사용된다면 엄청난 성능 향상을 가져온다
#### 클라이언트 측, 프록시, 그리고 서버 측 캐싱
어떤 캐싱 방식이 가장 적절한지는 최적화 하려는 대상에 좌우<br/><br/>
클라이언트 측 캐싱 
- 클라이언트가 캐싱된 결과를 저장하는 것
- 하위 서비스가 힌트를 제공, 클라이언트는 그 응답을 통해 해야 할 것을 이해하고 새로운 요청의 시점과 여부를 알 수 있다
- 네트워크 호출을 대폭 줄이고 서버의 하위 서비스에 대한 부하를 줄일 수 있는 가장 빠른 방법 중 하나

프록시 캐싱
- 클라이언트, 서버 사이에 프록시를 배치 하는 것
- 클라이언트와 서버에 독립적

서버측 캐싱
- 서버가 캐싱의 책임을 지고 레디스, 멤캐시드 또는 단순한 인메모리 캐시 같은 시스템을 활용
- 클라이언트에 독립적
- 서비스 경계 내부 또는 근처에 캐시를 배치하면 데이터의 무효화 또는 캐시 적중률 추적과 추적화 같으 ㄴ것을 추측하기 더 쉽다
#### HTTP 캐싱
HTTP는 클라이언트와 서버 측에서 캐시할 수 있는 유용한 규약(컨트롤) 제공<br/>
규약들이 널리 사용되는 명세서에 포함된 사실은 캐시를 다루는 기존의 많은 소프트웨어의 이점을 이용할 수 있음을 의미<br/><br/>
cache-control 지시자
- HTTP를 사용하면 클라이언트에 대한 응답으로 해당 지시자를 사용할 수 있음
- 클라이언트가 리소스를 캐시해야 하는지와 얼마나 오래 캐시해야 하는지를 초단위로 명시

Expires 헤더
- 콘텐트 캐싱 기간을 설정하는 대신 특정 시간 및 날짜에 리소스가 무효화 되고 다시 패치되도록 설정

ETag
- 리소스의 값이 변경되었음을 지정하는데 사용
#### 쓰기용 
write-behind 캐시 방식 - 로컬 캐시에 먼저 쓰고 데이터는 나중에 하위소스에 플러쉬 <br/>
버퍼링된 쓰기가 절절히 보존되면서 하위 서비스를 사용할 수 없을 때도 쓰기에 큐를 추가, 서비스가 다시 사용가능해지면 보낼 수 있음
#### 회복성을 위한 캐싱
캐싱은 장애의 회복성을 구현하는데 사용될 수 있음<br/>
클라이언트 측 캐싱 방법에서 클라이언트는 서버의 하위 서비스가 가용하지 않다면 캐싱된 데이터지만 잠재적으로 이전 것일 수 있는 데이터를 사용할지 결정 가능
#### 원본 감추기
정상적 캐시의 경우 요청이 캐시미스되면 요청은 최신 데이터를 패치하기 위해 원본으로 향하고 호출자는 결과를 기다리며 블로킹 됨
- 만약 캐시를 제공하는 전체 머신 또는 일부 그룹의 머신들이 고장나서 대규모 캐시 미스가 발생한다면 많은 요청들이 원본에 유입될 것<br/>
-> 대량 캐시가 가능한 데이터를 제공하는 서비스의 경우 대부분의 요청을 원본 앞에 위치한 캐시가 메모리에서 서비스하므로 원본 자체는 단지 전체 트래픽의 일부만 처리하도록 확장하는 것이 일반적
- 만약 전체 캐시 영역이 사라져서 엄청난 요청이 원본에 적중되면 원본도 불가한 상태<br/>
-> 원본을 보호하는 방법 : 처음부터 요청의 원본 유입을 허용하지 않는 것, 대신 원본 스스로 필요할 떄 비동기적으로 캐시를 채운다
#### 단순화하라
>> 너무 많은 곳에 캐싱하는 것을 주의!!!

최신 데이터 소스 사이에 캐시가 더 많은 수록 오래된 데이터가 더 많아지고 클라이언트가 최종적으로 볼 데이터의 신선도를 결정하는 것이 어려워 진다
#### 캐시 중독: 경계할 일화
>> 캐싱은 정말로 매우 강력할 수 있지만 그 복잡성과 문제가 될 것을 제대로 파악하기 위해 소스에서 목적지까지 캐시되는 전체 경로를 이해할 필요가 있다.
***
<br/>

### 자동 확장
반응적, 예측적 확장은 모두 유용<br/>
데이터를 수집하느 ㄴ동안 자동 확장을 장애 조건에 우선 사용하자(제안..)<br/>
부하에 따라 확장하기 시작한다면 너무 빨리 축소되지 않도록 주의
>> 대부분의 상황에서는 필요한 것보다 더 많으 ㄴ컴퓨팅 파워를 보유하는 것이 모자라는 것 보다 훨씬 낫다
***
<br/>

### CAP 정리
분산 시스템에서 서로 균형을 맞출 세 가지
- 일관성 : 다수의 노드로부터 동일한 대답을 얻어야 한다는 시스템의 특성 
- 가용성 : 모든 요청이 응답을 받는다는 것을 의미 
- 분할용인 : 시스템 부분 간의 통신이 가끔씩 실패한다는 사실을 다루는 시스템의 능력
>> CAP정리는 '우리는 실패모드에서 두 가지를 취하게 된다' 고 말한다.

#### 일관성 희생하기
분할용인과 가용성을 유지하기 위해 일관성을 희생하는 시스템 -> 최종의 일관성<br/>
미래의 특정 시점에 모든 노드가 업데이트된 데이터를 볼 것으로 예상되지만 한번에 수행되지 않으므로 우리는 사용자가 이전 데이터를 볼 가능성을 염두해 두어야 한다.
#### 가용성 희생하기
시스템이 일관성이 있으며 분할을 허용하는 CP 시스템일 경우, 서비스느 분할이 복구되고 데이터베이스 노드가 재동기화될 때까지 기능을 저하시키는 방법을 찾아가야 할 것<br/>
다수 노드의 일관성을 제대로 유지하는 것은 매우 어려우므로 필요하더라도 직접 발명을 시도하지 말 것을 강력히 제안 / 대신 이러한 특징을 제공하는 데이터 저장소나 잠금 서비스 선택을 권장
#### 분할용인 희생하기?
AP시스템 - 최종적 일관성이 있음<br/>
CP시스템 - 일관성이 있지만 구축, 확장이 어려움
#### AP 또는 CP?
어떤 것이 옳을지는 상황에 따라 다르다.<br/>
AP 시스템 
- 재고 목록 시스템에서 한 레코드가 5분 전이라도 괜찮을 경우 해답
- 은행에 있는 고객의 잔고일 경우는 안됨
#### 양자택일이 아니다
개별 서비스들이 모두 CP 또는 AP가 될 필요가 없다<br/>
CAP 정리와 연관된 절충안을 각 서비스의 기능에 주입하는 것
#### 그리고 현실세계
시스템들이 그 자체로 일관성을 유지하더라도 벌어지는 모든 것을 알 수 없다는 것을 인식해야 함<br/>
AP 시스템이 많은 상황에서 결국 올바른 결정이 되는 주요 이유 중 하나<br/>
CP 시스템은 구축하기 복잡할 뿐 아니라 문제를 모두 해결하지 못함
***
<br/>

### 서비스 발견
마이크로서비스는 서비스 발견을 자유롭게 다룰 수 있는 많은 옵션이 있다.
- 솔루션들은 인스턴스가 직접 등록하고 '나 여기 있어!' 라고 말할 수 있는 메커니즘 제공
- 솔루션들은 일단 등록된 서비스를 찾을 수 있는 방법 제공

서비스의 새로운 인스턴스를 종료/배포하는 환경을 고려할 때 서비스 발견은 더 복잡
#### DNS
DNS는 이름을 하나 이상 머신 IP 주소와 연결할 수 있게 해준다<br/>
DNS가 거의 모든 기술 스택이 지원하는 매우 쉽게 이해되고 많이 사용되는 표준이라는 것<br/>
DNS를 관리하는 많은 서비스가 있지만 그 중 일부는 일회용 호스트를 다루는 환경을 위해 설계된 것으로 보이며 DNS 엔트리를 업데이트하는 것이 다소 힘들다. <br/>
DNS 엔트리를 업데이트 할 때 발생하는 문제 외에 DNS 명세서 자체가 몇가지 문제를 일으킬 수 있다.<br/>
-> DNS 엔트리에는 TTL이 있는데 이 시간은 클라이언트가 얼마나 오래 이 엔트리를 최신의 것으로 간주할 수 있는지 지정, DNS 엔트리는 여러 위치에 캐시될 수 있는데 예를 들어 JVM 조차 사용자가 명시적으로 설정하지 않는다면 DNS 엔트리를 캐시한다. 캐시할 장소가 많을수록 더 많은 엔ㄷ트리가 이전 것을 가질 것이다.<br/>
-> 이 문제를 피할 수 있는 한가지 방법 : 부하 분산기를 가리키는 서비스의 도메인 이름 엔트리로 서비스의 인스턴스를 가리키는 것
***
<br/>

### 동적 서비스 레지스트리
#### 주키퍼
#### 칸슬
#### 유레카
#### 직접 만들기
#### 사람을 잊지 마라!
***
<br/>

### 문서화 서비스
#### 스웨거
#### HAL과 HAL 브라우저
***
<br/>

### 자기 기술 시스템
***
<br/>

### 마치며
***
<br/>
